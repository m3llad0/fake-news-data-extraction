{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m3llad0/fake-news-data-extraction/blob/main/Fake_news_detection_model_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBQrkFzbwDER"
      },
      "source": [
        "# Modelo de Detección de Noticias Falsas en Español\n",
        "\n",
        "Este notebook implementa un sistema híbrido basado en modelos de lenguaje (BETO) y Graph Neural Networks (GNNs) para detectar noticias falsas en español. Se justifica el uso de una arquitectura híbrida por la necesidad de capturar tanto patrones lingüísticos (BETO) como metadatos y relaciones contextuales (GNN)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Configuración del entorno y librerías\n",
        "\n",
        "Se importan las librerías necesarias para construir el modelo de detección de noticias falsas.\n",
        "\n",
        "- `torch`: framework principal para redes neuronales y entrenamiento en GPU.\n",
        "- `transformers`: permite cargar modelos preentrenados como BETO desde HuggingFace.\n",
        "- `numpy`, `pandas`: utilizadas para manipulación de datos.\n",
        "- `requests`: utilizada para acceder al dataset alojado vía una API externa.\n",
        "\n",
        "También se verifica la disponibilidad de GPU, lo cual es relevante para acelerar el entrenamiento de modelos grandes como BETO. Si se dispone de una GPU (por ejemplo, Tesla T4 en Colab), el entrenamiento y la inferencia serán considerablemente más rápidos."
      ],
      "metadata": {
        "id": "Zs4owuEmCaZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "C1Z0wYMil7c4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YETKo-iGOtyW",
        "outputId": "8f5ac068-1b93-437a-ea97-7a7bfe4e0c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "GPU Available: True\n",
            "GPU Name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"GPU Available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wHPUrPiwZOR"
      },
      "source": [
        "## 1. Carga de datos\n",
        "\n",
        "El conjunto de datos se obtiene mediante una solicitud HTTP (`GET`) a una API propia alojada en Azure. Esta API expone una lista de noticias previamente recolectadas y etiquetadas, bajo el campo `\"Scrapped news\"`.\n",
        "\n",
        "Cada noticia contiene:\n",
        "- `TITULO`: encabezado de la noticia.\n",
        "- `CORPUS`: cuerpo del texto.\n",
        "- `VERACIDAD`: etiqueta binaria (`'true'` o `'false'`).\n",
        "\n",
        "### 1.1 Preprocesamiento\n",
        "Se realiza un preprocesamiento inicial para construir el texto de entrada y la etiqueta de clase:\n",
        "- Se concatena el título y el cuerpo para formar una sola secuencia (`text`).\n",
        "- Se mapea la etiqueta `VERACIDAD` a valores numéricos:  \n",
        "  - `0` para noticias reales  \n",
        "  - `1` para noticias falsas\n",
        "\n",
        "Este formato es necesario para alimentar el modelo de lenguaje que se usará en las siguientes etapas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RZSfx5xmwcCA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# API endpoint\n",
        "ROUTE = \"https://my-thesis-aaacd0bxgzfae8a0.westus-01.azurewebsites.net/dataset\"\n",
        "\n",
        "# Fetch the data\n",
        "response = requests.get(ROUTE)\n",
        "data = response.json()\n",
        "\n",
        "# Extract 'Scrapped news' list\n",
        "news_items = data[\"Scrapped news\"]\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(news_items)\n",
        "\n",
        "# Preprocess the dataset for model input\n",
        "df['text'] = df['TITULO'] + \". \" + df['CORPUS']\n",
        "df['label'] = df['VERACIDAD'].map({'true': 0, 'false': 1, \"satira\":2})  # Map veracity to binary labels\n",
        "\n",
        "\n",
        "# Final dataset ready for model\n",
        "dataset = df[['text', 'label']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "WNo0o2wXL2FX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "033c801c-9f62-4925-b0a5-24de1f735e5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  Oxford lanza sus propios exámenes de certifica...      0\n",
              "1  La RAE estudia incluir «machirulo» en el Dicci...      0\n",
              "2  Realizan paro en Facultad de Ciencias Política...      0\n",
              "3  Deniegan el B1 a un joven mudo por no poder ap...      1\n",
              "4  Jorge Vergara recapacita y ofrece precios más ...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b16bda6d-582e-4905-971c-ec8963a7ee1e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Oxford lanza sus propios exámenes de certifica...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>La RAE estudia incluir «machirulo» en el Dicci...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Realizan paro en Facultad de Ciencias Política...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Deniegan el B1 a un joven mudo por no poder ap...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jorge Vergara recapacita y ofrece precios más ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b16bda6d-582e-4905-971c-ec8963a7ee1e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b16bda6d-582e-4905-971c-ec8963a7ee1e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b16bda6d-582e-4905-971c-ec8963a7ee1e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-327c2d61-bf18-403f-aa59-4d1f75419380\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-327c2d61-bf18-403f-aa59-4d1f75419380')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-327c2d61-bf18-403f-aa59-4d1f75419380 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 1298,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1017,\n        \"samples\": [\n          \"Chilangos que se recuperan de covid est\\u00e1n adquiriendo superpoderes. Debido a la pandemia de covid, era de esperarse que la vida de la ciudadan\\u00eda cambiara, pues la mayor\\u00eda de la gente no estaba acostumbrada a tanto encierro.\\n\\nEn el caso particular de los chilangos, esos cambios no fueron de la manera en que lo esperaban. Al parecer, la mezcla de tamalina \\u2014compuesto activo presente en los tamales\\u2014, las vacunas administradas, y el mismo virus, han hecho que muchos de los habitantes de la ciudad hayan comenzado a desarrollar superpoderes.\\n\\nAntonio Estrada, investigador de la UACM, ha sido quien descubri\\u00f3 este fen\\u00f3meno, y tuvo a bien compartirlo con la redacci\\u00f3n de El Dizque.\\n\\n\\u00abLa particular dieta de los chilangos, combinada con la contaminaci\\u00f3n ambiental y con tanta madre que tienen las vacunas, ya son un coctel peligroso. \\u00a1Pero ahora s\\u00famenle el virus! Todo eso ha ocasionado toda serie de reacciones, y debemos de estar preparados para una ola enorme de superh\\u00e9roes y supervillanos\\u201d.\\n\\nPor lo pronto, ya hemos visto las primeras acciones del Doctor Chaka, que ya no se sube a robar a los peseros, sino que se los lleva completos, mientras que el Capit\\u00e1n Canasta ha detenido a m\\u00e1s de un malandro arroj\\u00e1ndoles tacos de canasta cargados con energ\\u00eda radioactiva que los hace explosivos. Y es s\\u00f3lo el comienzo: \\u00abOlv\\u00eddense de las pel\\u00edculas de los Avengers, porque lo que ver\\u00e1 en esta ciudad los va a dejar a todos bien pen\\u2026\\u00bb, finaliz\\u00f3.\",\n          \"\\u00bfCre\\u00f3 un sismo artificial la celebraci\\u00f3n del gol de M\\u00e9xico frente a Alemania?. (CNN) \\u2013 Un tuit que describ\\u00eda un terremoto artificial en la Ciudad de M\\u00e9xico, despu\\u00e9s de que M\\u00e9xico anotara lo que ser\\u00eda el gol ganador del partido en la Copa del Mundo contra Alemania, se volvi\\u00f3 viral el domingo. Pero ni el Servicio Geol\\u00f3gico de los EE.UU. ni el Servicio Geol\\u00f3gico Nacional de M\\u00e9xico informaron de un sismo en la Ciudad de M\\u00e9xico ese d\\u00eda.\\n\\nEntonces, \\u00bfqu\\u00e9 pas\\u00f3? \\u00bfCelebr\\u00f3 M\\u00e9xico tan fuerte que caus\\u00f3 un sismo artificial?\\n\\nEl evento no fue lo suficientemente grande como para medirse en magnitudes y no habr\\u00eda sido perceptible para la poblaci\\u00f3n en general, de acuerdo con el Instituto de Investigaciones Geol\\u00f3gicas y Atmosf\\u00e9ricas, que no es una agencia del gobierno.\\n\\nMIRA: La Ciudad de M\\u00e9xico celebra el triunfo del \\u201cTri\\u201d\\n\\nEl domingo, el instituto tuite\\u00f3 lecturas sismogr\\u00e1ficas que destacaban la actividad cuando los mexicanos celebraron el que ser\\u00eda el gol decisivo del delantero Hirving Lozano.\\n\\nAtribuy\\u00f3 la causa posiblemente a \\u201csaltos masivos\\u201d de celebraci\\u00f3n en una publicaci\\u00f3n que obtuvo m\\u00e1s de 27.000 retuits.\\n\\nAl menos dos de sus sensores dentro de la Ciudad de M\\u00e9xico detectaron un movimiento s\\u00edsmico durante el partido de la Copa Mundial, \\u201cprobablemente producido por la celebraci\\u00f3n masiva\\u201d, seg\\u00fan la publicaci\\u00f3n del blog del instituto.\\n\\nMIRA: Hirving Lozano, el h\\u00e9roe de la victoria hist\\u00f3rica de M\\u00e9xico ante Alemania\\n\\nDijo que \\u201ctales eventos no son muy grandes. Solo los equipos sismogr\\u00e1ficos sensibles (y generalmente cercanos) pueden detectar los efectos de las multitudes\\u201d.\\n\\nEntonces, los instrumentos m\\u00e1s cercanos, por lo tanto, solo un \\u201cmuy peque\\u00f1o n\\u00famero de sism\\u00f3grafos\\u201d, pueden medir el evento, que el instituto describi\\u00f3 como \\u201cmicroregistros\\u201d.\\n\\nLa publicaci\\u00f3n del blog tambi\\u00e9n se\\u00f1al\\u00f3 que un evento similar ocurri\\u00f3 durante un juego de la NFL 2011 cuando una anotaci\\u00f3n de Marshawn Lynch provoc\\u00f3 que los fan\\u00e1ticos de Seattle Seahawks estallaran en celebraci\\u00f3n y eso caus\\u00f3 que un sism\\u00f3metro cercano midiera las vibraciones en lo que se llam\\u00f3 \\u201cQuaast de la Bestia\\u201d.\\n\\nLos fan\\u00e1ticos de Seattle volvieron a sacudir las cosas en 2013, registr\\u00e1ndose en una estaci\\u00f3n de grabaci\\u00f3n sismol\\u00f3gica cerca del estadio de los Seahawks durante una victoria sobre los New Orleans Saints.\\n\\nSismo o no, el entusiasmo en M\\u00e9xico se sinti\\u00f3 por todos lados el domingo cuando los fan\\u00e1ticos se deleitaban con el malestar general sobre Alemania.\\n\\nMarilia Brocchetto y Flora Charner de CNN contribuyeron a este informe.\",\n          \"Pedro S\\u00e1nchez busca reformar econom\\u00eda en Espa\\u00f1a tras covid-19. El presidente de Espa\\u00f1a, Pedro S\\u00e1nchez, compareci\\u00f3 hoy en el Palacio de la Moncloa para informar del Plan de Recuperaci\\u00f3n, Transformaci\\u00f3n y Resiliencia de la econom\\u00eda que pr\\u00f3ximamente presentar\\u00e1 a la Uni\\u00f3n Europea (UE), el cual trata el proyecto m\\u00e1s ambicioso e importante de la historia reciente del pa\\u00eds, seg\\u00fan el mandatario, tras su ingreso en dicho organismo.\\n\\n\\u201cEl Plan de Recuperaci\\u00f3n es el plan econ\\u00f3mico m\\u00e1s ambicioso y trascendental de las recientes historia econ\\u00f3mica para Espa\\u00f1a. Es la mayor oportunidad para Espa\\u00f1a desde la entrada de Espa\\u00f1a en la UE, y de eso hace 37 a\\u00f1os. Ocasiones como \\u00e9sta se presentan un par de veces en el siglo y esta oportunidad Espa\\u00f1a no la va a dejar pasar\\u201d, declar\\u00f3 S\\u00e1nchez.\\n\\nRecord\\u00f3 que en aquella \\u00e9poca los fondos estructurales fueron 8 mil millones de euros (m\\u00e1s de 191 mil millones de pesos) y \\u201cahora hablamos de 140 mil millones (superior a los 3 mil billones de pesos), fundamentales para recuperar los niveles de PIB previos a la pandemia y dar un crecimiento exponencial en las posibilidades de crecer, crear empleos y empresas. Una inversi\\u00f3n absolutamente excepcional y \\u00fanica\\u201d.\\n\\nEl mandatario dijo que en los \\u00faltimos a\\u00f1os Espa\\u00f1a ha sido golpeada por la peor crisis econ\\u00f3mica en 80 a\\u00f1os y un calificativo que tambi\\u00e9n consider\\u00f3 por la actual pandemia en un siglo. Estos sucesos desvelaron fragilidades de la econom\\u00eda y los servicios p\\u00fablicos del pa\\u00eds, seg\\u00fan S\\u00e1nchez.\\n\\n\\u00bfCu\\u00e1les son los objetivos del plan econ\\u00f3mico de Espa\\u00f1a?\\n\\nLos cinco grandes objetivos del Plan que S\\u00e1nchez resumi\\u00f3 son:\\n\\nModernizar el tejido productivo , incluyendo la administraci\\u00f3n p\\u00fablica.\\n\\n, incluyendo la administraci\\u00f3n p\\u00fablica. Aumentar la productividad , uno de los principales talones de Aquiles que explican por qu\\u00e9 hay un renta per c\\u00e1pita m\\u00e1s baja que el resto de potencias europeas.\\n\\nImpulsar la capacidad de crear empleo de calidad en todo el territorio, luchando contra el desempleo estructural, de j\\u00f3venes y de g\\u00e9nero.\\n\\nReducir las brechas sociales y de g\\u00e9nero , ampliadas por la crisis y la emergencia sanitaria\\n\\nImpulsar una transformaci\\u00f3n medioambiental.\\n\\n\\u201cEn el corto plazo queremos promover la recuperaci\\u00f3n econ\\u00f3mica tras la emergencia sanitaria\\u201d, dijo y agreg\\u00f3 que el fin \\u201ca medio plazo es mejorar la productividad de la econom\\u00eda espa\\u00f1ola con la transici\\u00f3n ecol\\u00f3gica y la transformaci\\u00f3n digital\\u201d.\\n\\nAgreg\\u00f3 que \\u201cen el largo plazo lo que queremos es que Espa\\u00f1a tenga un crecimiento robusto econ\\u00f3mico, sostenible en lo fiscal y resiliente en lo medioambiental\\u201d.\\n\\n\\u00bfCu\\u00e1les son los inversores principales?\\n\\nEl mandatario tambi\\u00e9n explic\\u00f3 que hay un total de 20 inversiones principales para los pr\\u00f3ximos tres a\\u00f1os. Detall\\u00f3 que en primer lugar habr\\u00e1 una estrategia de movilidad sostenible, segura y conectada, electrificando v\\u00edas p\\u00fablicas, dando puntos de recarga a veh\\u00edculos el\\u00e9ctricos, por 13 mil 200 millones de euros.\\n\\nEn la modernizaci\\u00f3n de la administraci\\u00f3n p\\u00fablica ser\\u00e1 de 4 mil 315 millones, mientras que en el plan de digitalizaci\\u00f3n de las pymes (peque\\u00f1as y medianas empresas) se planea con 4 mil 60 millones; la hoja de ruta del 5G, para impulsar la digitalizaci\\u00f3n, con 4 mil millones de euros; una nueva pol\\u00edtica industrial para la Espa\\u00f1a de 2030, con remodelaci\\u00f3n de gesti\\u00f3n de residuos, con 3 mil 780 millones.\\n\\nTambi\\u00e9n se contempla un plan de formaci\\u00f3n digital, con 3 mil 590 millones de euros; para la mejora de la competitividad se considera 3 mil 400 millones; el desarrollo de sistema de ciencia e innovaci\\u00f3n, con 3 mil 380 millones de euros; se tomar\\u00e1n 3 mil 400 millones de euros al sector tur\\u00edstico y, por \\u00faltimo, se destinar\\u00e1n 3 mil 175 millones a la transici\\u00f3n medioambiental.\\n\\nAsimismo, S\\u00e1nchez dijo que hay cuatro grandes transformaciones que consider\\u00f3 imprescindibles: la transici\\u00f3n verde, la transformaci\\u00f3n digital, la cohesi\\u00f3n territorial y la igualdad de g\\u00e9nero.\\n\\nLAS REFORMAS\\n\\nSon 20 las principales reformas que contempla el plan de Recuperaci\\u00f3n, aunque hay un centenar. No obstante, el presidente destac\\u00f3 la modernizaci\\u00f3n del sistema nacional de salud; un nuevo sistema energ\\u00e9tico, con despliegue de energ\\u00edas renovables; la modernizaci\\u00f3n de la justicia; la nueva econom\\u00eda de los cuidados, incluyendo las lecciones que deja la pandemia en las residencias; un plan de depuraci\\u00f3n y reutilizaci\\u00f3n de aguas, un debate clave en islas y territorios agr\\u00edcolas ante la amenaza del cambio clim\\u00e1tico.\\n\\nAdem\\u00e1s, a\\u00f1adi\\u00f3 la modernizaci\\u00f3n y digitalizaci\\u00f3n de administraciones p\\u00fablicas; la pol\\u00edtica de residuos y el impulso a la econom\\u00eda circular, que permitir\\u00e1n mucho empleo de calidad en los pr\\u00f3ximos a\\u00f1os; econom\\u00eda sostenible y conectada; la apuesta por la innovaci\\u00f3n y una nueva pol\\u00edtica de vivienda \\u201cen toda su extensi\\u00f3n\\u201d.\\n\\nLas previsiones del gobierno espa\\u00f1ol se traducir\\u00e1n, seg\\u00fan Pedro S\\u00e1nchez, en un crecimiento adicional del PIB de dos puntos a partir de 2021 (con crecimientos superiores al 2 por ciento anual desde 2030; la creaci\\u00f3n de 800 mil puestos de trabajo y la mejora de la vertebraci\\u00f3n del pa\\u00eds y el reparto de poblaci\\u00f3n en todo el pa\\u00eds, haciendo frente al reto demogr\\u00e1fico.\\n\\nEl env\\u00edo del plan definitivo a la UE, que inicialmente se preve\\u00eda entregar a finales de marzo, se retrasar\\u00e1 finalmente hasta su aprobaci\\u00f3n en el Consejo de Ministros del pr\\u00f3ximo martes 20 o 27 de abril.\\n\\n\\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Creación de modelo"
      ],
      "metadata": {
        "id": "BjXa7M6-D0q9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9YcLFvdxG5p"
      },
      "source": [
        "## 2.1 Inicialización del modelo BETO\n",
        "\n",
        "Se carga el modelo `dccuchile/bert-base-spanish-wwm-cased`, una versión de BERT entrenada en corpus en español con *Whole Word Masking* (WWM), lo que permite capturar mejor las propiedades léxicas y sintácticas del idioma.\n",
        "\n",
        "También se carga el tokenizador correspondiente, que convierte cada texto en una secuencia de tokens con padding y truncamiento adecuados. Esta etapa garantiza que la entrada al modelo sea coherente y consistente con el preentrenamiento original.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "hkJlMsZAwuUm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd5425c6-3a14-403c-968a-464acc45580c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
        "beto_model = AutoModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Definición de arquitectura de clasificación (BETO + MLP)\n",
        "\n",
        "La arquitectura del modelo se compone de dos partes:\n",
        "\n",
        "1. **BETO** actúa como extractor de características (encoder), generando embeddings para cada token del texto.\n",
        "2. **Cabeza de clasificación (MLP):**\n",
        "   - Se extrae el vector `[CLS]` como representación del texto completo.\n",
        "   - Se pasa por dos capas densas:\n",
        "     - `Linear(768 → 256)` con activación ReLU y Dropout.\n",
        "     - `Linear(256 → 2)` para salida binaria (real o falsa).\n",
        "\n",
        "> Esta estructura forma un **MLP (Multilayer Perceptron)** superficial que aprende a clasificar el embedding global en una de las dos clases.\n",
        "\n",
        "El modelo se entrena con:\n",
        "- `CrossEntropyLoss`: para clasificación multiclase.\n",
        "- `AdamW`: optimizador adaptado con regularización L2.\n",
        "\n",
        "La arquitectura se mueve a GPU si está disponible.\n"
      ],
      "metadata": {
        "id": "JeKsJU5PEB8n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "jupeLlLpxUny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a50be88-4564-4f46-9d5f-714c0db37888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo listo. Capas adicionales:\n",
            " Linear(in_features=768, out_features=256, bias=True) Linear(in_features=256, out_features=3, bias=True)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Definición del modelo\n",
        "dropout = nn.Dropout(0.3)\n",
        "dense1 = nn.Linear(beto_model.config.hidden_size, 256)\n",
        "dense2 = nn.Linear(256, 3)  # 2 clases (softmax implícito en la pérdida)\n",
        "\n",
        "# Mover a GPU\n",
        "beto_model.to(device)\n",
        "dropout.to(device)\n",
        "dense1.to(device)\n",
        "dense2.to(device)\n",
        "\n",
        "# Definición de función forward\n",
        "def model_forward(input_ids, attention_mask):\n",
        "    outputs = beto_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    cls_output = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
        "\n",
        "    x = dropout(cls_output)\n",
        "    x = F.relu(dense1(x))\n",
        "    x = dropout(x)\n",
        "    logits = dense2(x)\n",
        "\n",
        "    return logits\n",
        "\n",
        "# Pérdida y optimizador\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(\n",
        "    list(beto_model.parameters()) + list(dense1.parameters()) + list(dense2.parameters()),\n",
        "    lr=2e-5\n",
        ")\n",
        "\n",
        "# Mostrar resumen básico\n",
        "print(\"Modelo listo. Capas adicionales:\\n\", dense1, dense2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 División del dataset y tokenización\n",
        "\n",
        "Se divide el conjunto de datos en entrenamiento (80%) y validación (20%) usando `train_test_split` estratificado, para preservar la proporción entre clases reales y falsas.\n",
        "\n",
        "Luego, los textos se tokenizan utilizando el tokenizador de BETO:\n",
        "- Truncamiento a máximo 512 tokens.\n",
        "- Padding automático.\n",
        "- Salida como tensores PyTorch (`return_tensors=\"pt\"`).\n",
        "\n",
        "Esta representación será utilizada como entrada al modelo en la etapa de entrenamiento. La tokenización garantiza que el texto esté alineado con el vocabulario y segmentación aprendidos durante el preentrenamiento de BETO.\n"
      ],
      "metadata": {
        "id": "wBrOIMqkEQ2g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "r2lXeYeoNyXF"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df['text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
        ")\n",
        "\n",
        "# Flatten labels\n",
        "train_labels = train_labels.values.flatten()\n",
        "val_labels = val_labels.values.flatten()\n",
        "\n",
        "# Tokenize text con salida en PyTorch\n",
        "train_encodings = tokenizer(\n",
        "    list(train_texts),\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=512,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "val_encodings = tokenizer(\n",
        "    list(val_texts),\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=512,\n",
        "    return_tensors=\"pt\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7rjqmfANvDQ"
      },
      "source": [
        "## 3. Entrenamiento del modelo textual (BETO + MLP)\n",
        "\n",
        "### 🔧 Preparación\n",
        "- Se entrena el modelo por un máximo de **20 épocas** con un `batch size` de 8.\n",
        "- Se aplica **regularización L2** (`weight_decay=1e-4`) y **Dropout del 30%** para mitigar el sobreajuste.\n",
        "- Se calculan los pesos por clase con `class_weight='balanced'` para compensar el posible desbalance entre noticias reales y falsas.\n",
        "- Se utiliza `CrossEntropyLoss` ponderada como función de pérdida y `Adam` como optimizador.\n",
        "\n",
        "### 3.1 Bucle de entrenamiento\n",
        "Por cada época:\n",
        "1. Se realiza entrenamiento en el conjunto de entrenamiento y evaluación en el de validación.\n",
        "2. Se almacenan métricas clave: pérdida (`loss`) y precisión (`accuracy`) en ambos conjuntos.\n",
        "3. Se imprime el desempeño actual incluyendo la tasa de aprendizaje.\n",
        "4. Se aplica `ReduceLROnPlateau` como **scheduler dinámico** que reduce la tasa de aprendizaje si la pérdida de validación no mejora.\n",
        "5. Se implementa **early stopping** con `patience = 3`, deteniendo el entrenamiento si no se detecta mejora.\n",
        "\n",
        "### 3.2 Restauración del mejor modelo\n",
        "Al finalizar el entrenamiento (o al activarse early stopping), se restauran los pesos del modelo con mejor desempeño en validación, preservando así el mejor punto del entrenamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51xyCJgMPo8u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7af608d2-27cf-4dfc-d683-2b276a9aa15c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | LR: 0.000020 | Train Loss: 0.9162 | Val Loss: 0.7242 | Train Acc: 0.5395 | Val Acc: 0.6385\n",
            "Epoch 2 | LR: 0.000020 | Train Loss: 0.5736 | Val Loss: 0.5397 | Train Acc: 0.7601 | Val Acc: 0.7962\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 8\n",
        "PATIENCE = 3\n",
        "\n",
        "dropout = torch.nn.Dropout(0.3)  # Increased regularization\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    list(beto_model.parameters()) + list(dense1.parameters()) + list(dense2.parameters()),\n",
        "    lr=2e-5,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_labels),\n",
        "    y=train_labels\n",
        ")\n",
        "\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = TensorDataset(\n",
        "    train_encodings['input_ids'],\n",
        "    train_encodings['attention_mask'],\n",
        "    torch.tensor(train_labels)\n",
        ")\n",
        "\n",
        "val_dataset = TensorDataset(\n",
        "    val_encodings['input_ids'],\n",
        "    val_encodings['attention_mask'],\n",
        "    torch.tensor(val_labels)\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Scheduler\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1)\n",
        "\n",
        "# Metrics\n",
        "train_losses, val_losses = [], []\n",
        "train_accuracies, val_accuracies = [], []\n",
        "\n",
        "best_val_loss = np.inf\n",
        "best_model_state = None\n",
        "patience_counter = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    beto_model.train()\n",
        "    dense1.train()\n",
        "    dense2.train()\n",
        "\n",
        "    running_loss = 0\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_forward(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "    train_acc = correct / total\n",
        "\n",
        "    # Validation\n",
        "    beto_model.eval()\n",
        "    dense1.eval()\n",
        "    dense2.eval()\n",
        "\n",
        "    val_running_loss = 0\n",
        "    val_correct, val_total = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
        "            outputs = model_forward(input_ids, attention_mask)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    avg_val_loss = val_running_loss / len(val_loader)\n",
        "    val_acc = val_correct / val_total\n",
        "\n",
        "    # Save metrics\n",
        "    train_losses.append(avg_train_loss)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "    # Print status\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"Epoch {epoch+1} | LR: {current_lr:.6f} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | \"\n",
        "          f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # Scheduler step\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    # Early stopping\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        best_model_state = {\n",
        "            \"beto\": beto_model.state_dict(),\n",
        "            \"dense1\": dense1.state_dict(),\n",
        "            \"dense2\": dense2.state_dict()\n",
        "        }\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "# Restore best model\n",
        "beto_model.load_state_dict(best_model_state[\"beto\"])\n",
        "dense1.load_state_dict(best_model_state[\"dense1\"])\n",
        "dense2.load_state_dict(best_model_state[\"dense2\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Visualización de métricas y evaluación del modelo textual\n",
        "\n",
        "### 4.1 Precisión y pérdida a lo largo de las épocas\n",
        "\n",
        "Se grafican las curvas de `accuracy` y `loss` tanto para el conjunto de entrenamiento como para el de validación.\n",
        "\n",
        "#### 4.2 Observaciones:\n",
        "- La precisión en entrenamiento alcanza casi el 100%, mientras que en validación se estabiliza cerca del 86%.\n",
        "- La pérdida de entrenamiento disminuye continuamente, pero la de validación comienza a subir después de la época 2.\n",
        "\n",
        "> Estos patrones son consistentes con **sobreajuste**, indicando que el modelo aprende muy bien el set de entrenamiento pero generaliza moderadamente al set de validación.\n",
        "\n"
      ],
      "metadata": {
        "id": "L_dlWLpC-MGv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRoJ25UZQlnC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(train_accuracies, label='Training Accuracy')\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "plt.title('Accuracy over epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Loss\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Loss over epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Evaluación cuantitativa (classification report)\n",
        "\n",
        "Se calcula un reporte detallado con precisión, recall y F1-score por clase.\n",
        "\n",
        "- **Accuracy global:** 0.86\n",
        "- **Macro F1:** 0.86\n",
        "\n",
        "#### 4.3.1 Análisis:\n",
        "- El modelo **identifica muy bien noticias reales** (recall del 94%), pero **omite una proporción considerable de noticias falsas** (recall del 77%).\n",
        "- Esto sugiere que el modelo confunde algunas noticias falsas con verdaderas, posiblemente debido a redacción formal o ambigüedad semántica.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aZfyJ_6fJWSE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gU8xiGmQ5gC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "import torch\n",
        "\n",
        "# Modo evaluación\n",
        "beto_model.eval()\n",
        "dense1.eval()\n",
        "dense2.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
        "\n",
        "        outputs = model_forward(input_ids, attention_mask)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Reporte de métricas\n",
        "print(classification_report(all_labels, all_preds, target_names=[\"Real\", \"Fake\", \"Satira\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 Matriz de confusión\n",
        "\n",
        "La matriz muestra los errores más relevantes del modelo en validación.\n",
        "\n",
        "- **Falsos positivos:** 8 reales etiquetadas como falsas.\n",
        "- **Falsos negativos:** 23 falsas clasificadas como reales.\n",
        "\n",
        "> El mayor error está en las **falsas negativas**, lo que impacta negativamente el recall de la clase “Fake”.\n"
      ],
      "metadata": {
        "id": "yaiaoTnoJv8O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jErQuyR9Q8kY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Ya tienes all_preds y all_labels del paso anterior\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "labels = [\"Real\", \"Fake\", \"Satira\"]\n",
        "\n",
        "# Mostrar matriz de confusión\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5 Conclusión\n",
        "\n",
        "- El modelo logra un buen desempeño general como línea base, con un F1 de 0.86 y buena estabilidad.\n",
        "- El sobreajuste observado y los errores en noticias falsas justifican continuar con la incorporación de contexto estructural (GNN) y técnicas de regularización o augmentación."
      ],
      "metadata": {
        "id": "948n8P24J6u7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U7uadgJ9_90"
      },
      "source": [
        "## 5. Creación del modelo híbrido"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtR5maZQHOIV"
      },
      "source": [
        "### 5.1 Construcción de features estructurales para la GNN\n",
        "\n",
        "En esta sección se construye un conjunto de **metadatos enriquecidos** que representan cada noticia como un nodo con atributos numéricos. Estos atributos no se basan en el contenido textual en sí, sino en señales de contexto y estructura, lo que permite entrenar una red neuronal de grafos (GNN) que capte relaciones implícitas entre noticias.\n",
        "\n",
        "---\n",
        "\n",
        "### 5.1.1 Atributos incluidos\n",
        "\n",
        "1. **`LABEL`**  \n",
        "   Etiqueta binaria de veracidad (0 = real, 1 = falsa), igual que en el modelo textual.\n",
        "\n",
        "2. **`FUENTE_COD`**  \n",
        "   Codificación del autor o fuente de la noticia. Se usa `LabelEncoder` para transformar valores categóricos a enteros. Las fuentes desconocidas se rellenan con `\"desconocido\"`.\n",
        "\n",
        "3. **`FECHA_NUM`**  \n",
        "   Representación de la fecha de publicación como número de días desde una fecha base (`2023-01-01`). Esto permite tratar la fecha como una variable continua.\n",
        "\n",
        "4. **`LONGITUD`**  \n",
        "   Cantidad de palabras del texto completo (`título + cuerpo`). Las noticias extremadamente cortas o largas pueden correlacionarse con ciertos tipos de desinformación.\n",
        "\n",
        "5. **`POLARIDAD`**  \n",
        "   Sentimiento del texto calculado con `TextBlob` (rango de -1 a 1). Las noticias con polarización extrema podrían ser más susceptibles a contener sesgos o emociones.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "3XwgVeVTtN2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNGvccXWHQdu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Crear dataset limpio\n",
        "gnn_data = pd.DataFrame()\n",
        "\n",
        "# Texto y label\n",
        "gnn_data['TEXTO'] = df['TITULO'].fillna('').astype(str) + \". \" + df['CORPUS'].fillna('').astype(str)\n",
        "gnn_data['LABEL'] = df['VERACIDAD'].map({'true': 0, 'false': 1, \"satira\": 2})\n",
        "\n",
        "# Fuente / Dominio\n",
        "gnn_data['FUENTE'] = df['AUTOR'].fillna('desconocido').astype(str)\n",
        "le_fuente = LabelEncoder()\n",
        "gnn_data['FUENTE_COD'] = le_fuente.fit_transform(gnn_data['FUENTE'])\n",
        "\n",
        "# Fecha a número (días desde 2023-01-01)\n",
        "fecha_col = pd.to_datetime(df['FECHA'], errors='coerce')\n",
        "fecha_base = pd.Timestamp('2023-01-01')\n",
        "# Serie de días (puede contener NaN)\n",
        "fecha_num = (fecha_col - fecha_base).dt.days\n",
        "# Imputación simple (si todas son NaN → 0)\n",
        "if fecha_num.notna().any():\n",
        "    fecha_num = fecha_num.fillna(fecha_num.median())\n",
        "else:\n",
        "    fecha_num = pd.Series(0, index=df.index, dtype=float)\n",
        "\n",
        "gnn_data['FECHA_NUM'] = fecha_num.astype(float)\n",
        "\n",
        "# Longitud del texto\n",
        "gnn_data['LONGITUD'] = gnn_data['TEXTO'].str.split().str.len()\n",
        "\n",
        "# Polaridad\n",
        "def get_sentiment(text):\n",
        "    try:\n",
        "        return TextBlob(str(text)).sentiment.polarity\n",
        "    except Exception:\n",
        "        return 0.0\n",
        "\n",
        "gnn_data['POLARIDAD'] = gnn_data['TEXTO'].apply(get_sentiment)\n",
        "\n",
        "gnn_data.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1.2 Detección de Clickbait\n",
        "\n",
        "Se utiliza el modelo `taniwasl/clickbait_es` (HuggingFace) para calcular un **score de clickbait** a partir del título de la noticia.\n",
        "\n",
        "- Se define un pipeline con `TextClassificationPipeline` que devuelve todas las probabilidades por clase.\n",
        "- Se extrae la probabilidad correspondiente a la clase “clickbait”.\n",
        "- El resultado es un valor continuo entre 0 y 1 asignado a la columna `CLICKBAIT`.\n",
        "\n",
        "> Este puntaje refleja la probabilidad de que el título de una noticia tenga intención de atraer clics mediante lenguaje exagerado, sensacionalista o ambiguo.\n"
      ],
      "metadata": {
        "id": "0glsr0eYLICP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJeWPFmjMwWU"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
        "\n",
        "clickbait_model = \"taniwasl/clickbait_es\"\n",
        "\n",
        "tokenizer_cb = AutoTokenizer.from_pretrained(clickbait_model)\n",
        "model_cb = AutoModelForSequenceClassification.from_pretrained(clickbait_model)\n",
        "\n",
        "cb_pipeline = TextClassificationPipeline(\n",
        "    model=model_cb,\n",
        "    tokenizer=tokenizer_cb,\n",
        "    return_all_scores=True,\n",
        "    function_to_apply=\"softmax\",\n",
        "    top_k=None\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1.3 Resultado\n",
        "\n",
        "El dataframe `gnn_data` contiene ahora las siguientes variables por nodo:\n",
        "\n",
        "- TEXTO (para referencia)\n",
        "- LABEL (0 o 1)\n",
        "- FUENTE_COD (entero)\n",
        "- FECHA_NUM (entero)\n",
        "- LONGITUD (entero)\n",
        "- POLARIDAD (float)\n",
        "- CLICKBAIT (float)\n",
        "\n",
        "Este vector de características representa el perfil contextual de cada noticia y será utilizado como entrada para construir un grafo de similitud y entrenar el modelo GNN."
      ],
      "metadata": {
        "id": "-sRmnPVeLP6s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcwjqI5BN8Bd"
      },
      "outputs": [],
      "source": [
        "def clickbait_score(title: str) -> float:\n",
        "    res = cb_pipeline(title[:128])\n",
        "    for score_dict in res[0]:\n",
        "        if score_dict['label'].lower() in ['clickbait', 'click_bait', 'click-bait']:\n",
        "            return score_dict['score']\n",
        "    return res[0][0]['score']\n",
        "\n",
        "gnn_data['CLICKBAIT'] = df['TITULO'].apply(clickbait_score)\n",
        "\n",
        "gnn_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1.4 Normalización de metadatos y ensamblado del vector estructural\n",
        "\n",
        "Para que la red neuronal de grafos procese correctamente los metadatos, es necesario normalizar las variables numéricas a un rango comparable. Se utiliza `MinMaxScaler` para escalar los siguientes atributos al intervalo [0, 1]:\n",
        "\n",
        "- `FECHA_NUM` → `FECHA_NORM`\n",
        "- `LONGITUD` → `LONGITUD_NORM`\n",
        "- `POLARIDAD` → `POLARIDAD_NORM`\n",
        "- `CLICKBAIT` → `CLICKBAIT_NORM`\n",
        "\n",
        "Luego, se construye la **matriz final de metadatos** (`metadata_gnn`) concatenando:\n",
        "\n",
        "1. `FUENTE_COD` → codificación entera de la fuente (no normalizada).\n",
        "2. Atributos normalizados: fecha, longitud, polaridad y clickbait.\n",
        "\n",
        "Este vector representa cada nodo (noticia) en el grafo mediante un conjunto de **características estructurales y semánticas suaves**, que serán procesadas posteriormente por la GNN para capturar relaciones no evidentes entre noticias.\n",
        "\n",
        "> Esta representación es independiente del contenido textual y permite explotar patrones relacionados con estilo, fuente, tono y temporalidad.\n"
      ],
      "metadata": {
        "id": "bjG9YMKaL0OT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTt_7m1JObqX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Índices de train/test (estratificado en la etiqueta)\n",
        "idx_all = np.arange(len(gnn_data))\n",
        "train_idx, test_idx = train_test_split(\n",
        "    idx_all,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=gnn_data['LABEL']\n",
        ")\n",
        "\n",
        "# Features numéricas sin normalizar (orden explícito)\n",
        "# 1=LONGITUD, 2=POLARIDAD, 3=CLICKBAIT, 4=FECHA_NUM\n",
        "X_num = gnn_data[['LONGITUD', 'POLARIDAD', 'CLICKBAIT', 'FECHA_NUM']].to_numpy(dtype=float)\n",
        "\n",
        "# Split\n",
        "X_num_train = X_num[train_idx]\n",
        "X_num_test  = X_num[test_idx]\n",
        "\n",
        "# Escalado solo con TRAIN (evita fuga)\n",
        "scaler = MinMaxScaler().fit(X_num_train)\n",
        "X_num_train_scaled = scaler.transform(X_num_train)\n",
        "X_num_test_scaled  = scaler.transform(X_num_test)\n",
        "\n",
        "# Fuente codificada (queda como primera columna, SIN escalar)\n",
        "fuente_all = gnn_data['FUENTE_COD'].to_numpy().reshape(-1,1)\n",
        "fuente_train = fuente_all[train_idx]\n",
        "fuente_test  = fuente_all[test_idx]\n",
        "\n",
        "\n",
        "metadata_train = np.concatenate([fuente_train, X_num_train_scaled], axis=1).astype(np.float32)\n",
        "metadata_test  = np.concatenate([fuente_test , X_num_test_scaled ], axis=1).astype(np.float32)\n",
        "\n",
        "meta_train = metadata_train\n",
        "meta_test  = metadata_test\n",
        "\n",
        "\n",
        "metadata_gnn = np.concatenate([metadata_train, metadata_test], axis=0)\n",
        "\n",
        "print(\"metadata_train/test:\", metadata_train.shape, metadata_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Arquitectura Modelo Híbrido"
      ],
      "metadata": {
        "id": "Hz4UkURUL7_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Extracción de embeddings con BETO\n",
        "\n",
        "Se utiliza el modelo `beto_model` (ya entrenado o congelado) para generar representaciones vectoriales (`embeddings`) de cada noticia a partir del token `[CLS]`.\n",
        "\n",
        "Pasos:\n",
        "1. Se tokeniza todo el texto (`TÍTULO + CUERPO`) y se almacena en un `DataLoader`.\n",
        "2. Se desactiva el cálculo de gradientes (`torch.no_grad()`).\n",
        "3. Para cada batch, se extrae el embedding del token `[CLS]` y se almacena.\n",
        "4. Finalmente, se concatenan todos los vectores obtenidos (uno por noticia), obteniendo una matriz de embeddings de dimensión `(n_samples, 768)`.\n",
        "\n",
        "Estos vectores representan el **contenido textual** de cada noticia en un espacio semántico preentrenado.\n"
      ],
      "metadata": {
        "id": "48U9Kra9Mxuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_embeddings(text_list, batch_size=8):\n",
        "    encodings = tokenizer(\n",
        "        list(text_list),\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'])\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    beto_model.eval()\n",
        "    all_cls = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_ids_batch, attention_mask_batch in loader:\n",
        "            input_ids_batch = input_ids_batch.to(device)\n",
        "            attention_mask_batch = attention_mask_batch.to(device)\n",
        "\n",
        "            outputs = beto_model(input_ids=input_ids_batch, attention_mask=attention_mask_batch)\n",
        "            cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "            all_cls.append(cls_embeddings.cpu())\n",
        "\n",
        "    return torch.cat(all_cls, dim=0).numpy()"
      ],
      "metadata": {
        "id": "bVLqyNkGA4Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "labels = gnn_data['LABEL'].to_numpy()\n",
        "texts  = gnn_data['TEXTO'].to_numpy()\n",
        "\n",
        "texts_train = texts[train_idx]\n",
        "texts_test  = texts[test_idx]\n",
        "y_train = labels[train_idx]\n",
        "y_test  = labels[test_idx]\n",
        "\n",
        "# Usa tus funciones intactas\n",
        "X_text_train = generate_embeddings(texts_train)\n",
        "X_text_test  = generate_embeddings(texts_test)\n",
        "\n",
        "# Asegura dtype consistente\n",
        "X_meta_train = meta_train.astype(np.float32)\n",
        "X_meta_test  = meta_test.astype(np.float32)\n",
        "\n",
        "print(\"X_text_train/test:\", X_text_train.shape, X_text_test.shape)\n",
        "print(\"X_meta_train/test:\", X_meta_train.shape, X_meta_test.shape)\n"
      ],
      "metadata": {
        "id": "xRYma0vZAYeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkSwb4WORSV5"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# # Tokenizar todo pero sin pasar a tensor gigante\n",
        "# encodings = tokenizer(\n",
        "#     list(gnn_data['TEXTO']),\n",
        "#     truncation=True,\n",
        "#     padding=True,\n",
        "#     max_length=512,\n",
        "#     return_tensors=\"pt\"\n",
        "# )\n",
        "\n",
        "# # Crear DataLoader sin clases personalizadas\n",
        "# input_ids = encodings['input_ids']\n",
        "# attention_mask = encodings['attention_mask']\n",
        "\n",
        "# dataset = TensorDataset(input_ids, attention_mask)\n",
        "# loader = DataLoader(dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# # Modo evaluación\n",
        "# beto_model.eval()\n",
        "# all_embeddings = []\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     for batch in loader:\n",
        "#         input_ids_batch, attention_mask_batch = [x.to(device) for x in batch]\n",
        "#         outputs = beto_model(input_ids=input_ids_batch, attention_mask=attention_mask_batch)\n",
        "#         cls_batch = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "#         all_embeddings.append(cls_batch.cpu())\n",
        "\n",
        "# # Concatenar todos los embeddings\n",
        "# embeddings = torch.cat(all_embeddings, dim=0).numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 División del dataset para modelo híbrido\n",
        "\n",
        "Se utiliza `train_test_split` para dividir el conjunto completo de:\n",
        "- Embeddings del texto (`X_text`)\n",
        "- Metadatos estructurales (`X_meta`)\n",
        "- Etiquetas (`y`)\n",
        "\n",
        "Esto permite evaluar de manera justa el modelo híbrido posterior, asegurando que las relaciones en el grafo también estén divididas entre entrenamiento y prueba. El `random_state` se fija para reproducibilidad.\n"
      ],
      "metadata": {
        "id": "9lwpDYI8NicS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3 Construcción del grafo de similitud semántica\n",
        "\n",
        "Se construyen dos grafos de adyacencia (uno para entrenamiento y otro para prueba) basados en la **similitud coseno** entre los embeddings de texto.\n",
        "\n",
        "- Se calcula la matriz de similitud coseno entre pares de noticias.\n",
        "- Se aplica un umbral de corte: si la similitud es > 0.8, se considera que hay una arista entre los nodos (noticias).\n",
        "- Se elimina la diagonal (auto-conexiones).\n",
        "- Se convierte la matriz densa a formato disperso (`scipy.sparse`) para eficiencia.\n",
        "\n",
        "> Este grafo captura relaciones implícitas entre noticias con contenido textual altamente similar, incluso si no comparten fuente o fecha.\n"
      ],
      "metadata": {
        "id": "0u0qSYPKNoue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fuentes_train = meta_train[:, 0]\n",
        "fechas_train      = meta_train[:, 4]   # FECHA_NORM\n",
        "polaridades_train = meta_train[:, 2]\n"
      ],
      "metadata": {
        "id": "A5_3QOpToRx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwCCPLwsSXpb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "n = len(X_text_train)\n",
        "\n",
        "# Cosine similarity con umbral aleatorio por epoch\n",
        "sim_text = cosine_similarity(X_text_train)\n",
        "threshold = np.random.uniform(0.7, 0.85)\n",
        "adj_text_train = (sim_text > threshold).astype(np.float32)\n",
        "\n",
        "# Misma fuente\n",
        "adj_fuente_train = np.equal.outer(fuentes_train, fuentes_train).astype(np.float32)\n",
        "\n",
        "# Fecha cercana (diferencia ≤ 0.05 en escala normalizada)\n",
        "adj_fecha_train = (np.abs(fechas_train[:, None] - fechas_train[None, :]) <= 0.05).astype(np.float32)\n",
        "\n",
        "# Polaridad similar (diferencia ≤ 0.1)\n",
        "adj_polaridad_train = (np.abs(polaridades_train[:, None] - polaridades_train[None, :]) <= 0.1).astype(np.float32)\n",
        "\n",
        "# Combinar\n",
        "adj_enriched_train = np.clip(\n",
        "    adj_text_train + adj_fuente_train + adj_fecha_train + adj_polaridad_train,\n",
        "    0, 1\n",
        ")\n",
        "np.fill_diagonal(adj_enriched_train, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fuentes_test = meta_test[:, 0]\n",
        "fechas_test      = meta_test[:, 4]     # FECHA_NORM\n",
        "polaridades_test = meta_test[:, 2]   # Suponiendo ya está normalizada\n",
        "\n",
        "# 1. Similitud coseno (texto)\n",
        "sim_text_test = cosine_similarity(X_text_test)\n",
        "adj_text_test = (sim_text_test > 0.8).astype(np.float32)\n",
        "\n",
        "# 2. Misma fuente\n",
        "adj_fuente_test = np.equal.outer(fuentes_test, fuentes_test).astype(np.float32)\n",
        "\n",
        "# 3. Fecha cercana (normalizada)\n",
        "adj_fecha_test = (np.abs(fechas_test[:, None] - fechas_test[None, :]) <= 0.05).astype(np.float32)\n",
        "\n",
        "# 4. Polaridad similar\n",
        "adj_polaridad_test = (np.abs(polaridades_test[:, None] - polaridades_test[None, :]) <= 0.1).astype(np.float32)\n",
        "\n",
        "# 5. Combinar todo (OR lógico)\n",
        "adj_enriched_test = np.clip(\n",
        "    adj_text_test + adj_fuente_test + adj_fecha_test + adj_polaridad_test,\n",
        "    0, 1\n",
        ")\n",
        "np.fill_diagonal(adj_enriched_test, 0)\n"
      ],
      "metadata": {
        "id": "S47qWFidJMXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric"
      ],
      "metadata": {
        "id": "5YwFR32YMIe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.4 Definición del modelo híbrido (BETO + GCN)\n",
        "\n",
        "Se define una arquitectura que combina:\n",
        "- **Embeddings de texto (768 dim)** obtenidos por BETO.\n",
        "- **Metadatos procesados con GCN**, que modela la estructura del grafo.\n",
        "\n",
        "#### 6.4.1 Arquitectura:\n",
        "\n",
        "1. `meta_fc` (Linear): transforma los metadatos de entrada (5 características) a 64 dimensiones.\n",
        "2. `GCNConv`: aplica una convolución de grafos que propaga información entre nodos vecinos en el grafo de similitud.\n",
        "3. `concat_fc1`: concatena las salidas del GCN y el embedding textual para formar un vector enriquecido de 800 dimensiones.\n",
        "4. `output_fc`: capa final con activación `log_softmax` para clasificación binaria.\n",
        "\n",
        "Se usan funciones de activación ReLU y regularización con Dropout para mejorar la capacidad general del modelo.\n",
        "\n",
        "---\n",
        "\n",
        "#### 6.4.2 Ejecución (Forward Pass)\n",
        "\n",
        "1. Los metadatos normalizados se transforman con `meta_fc` y luego se propagan en el grafo con `GCNConv`.\n",
        "2. El resultado del GCN se concatena con los embeddings del texto de BETO.\n",
        "3. Esta representación combinada se pasa por capas densas y se obtiene el `logits` de clasificación (dimensión 2).\n",
        "\n",
        "Este diseño permite capturar **simultáneamente señales lingüísticas y estructurales**, lo que mejora significativamente el desempeño frente a un modelo puramente textual.\n"
      ],
      "metadata": {
        "id": "4_bzv1v-NvTB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WaZFuTsSanz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv  # 🔄 Cambiado de GCNConv a GATConv\n",
        "from torch_geometric.utils import dense_to_sparse, dropout_adj\n",
        "\n",
        "# Dimensiones\n",
        "metadata_dim = X_meta_train.shape[1]\n",
        "text_dim = 768\n",
        "\n",
        "# Definir capas\n",
        "meta_fc = nn.Linear(metadata_dim, 32)\n",
        "gcn_conv = GATConv(32, 16, heads=2, concat=False, dropout=0.3)  # 🔄 GATConv con atenció\n",
        "concat_fc1 = nn.Linear(text_dim + 16, 32)\n",
        "bn1 = nn.BatchNorm1d(32)\n",
        "dropout = nn.Dropout(0.5)\n",
        "output_fc = nn.Linear(32, 3)\n",
        "\n",
        "# Mover a GPU si está disponible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "meta_fc.to(device)\n",
        "gcn_conv.to(device)\n",
        "concat_fc1.to(device)\n",
        "bn1.to(device)\n",
        "dropout.to(device)\n",
        "output_fc.to(device)\n",
        "\n",
        "# Preparar datos\n",
        "text_embeddings = torch.tensor(X_text_train, dtype=torch.float32).to(device)\n",
        "meta_features = torch.tensor(X_meta_train, dtype=torch.float32).to(device)\n",
        "\n",
        "# Convertir adj_train a edge_index\n",
        "adj_dense = torch.tensor(adj_enriched_train, dtype=torch.float32)\n",
        "edge_index, edge_weight = dense_to_sparse(adj_dense)\n",
        "edge_index = edge_index.to(device)\n",
        "\n",
        "# 🔹 Aplicar edge dropout SOLO en entrenamiento\n",
        "# p=0.1 significa que elimina 10% de las aristas aleatoriamente\n",
        "is_training = True  # ponlo en False si es validación o test\n",
        "if is_training:\n",
        "    edge_index, _ = dropout_adj(edge_index, p=0.1, force_undirected=False)\n",
        "    edge_index = edge_index.to(device)\n",
        "\n",
        "\n",
        "# Forward pass\n",
        "x_gnn = F.relu(meta_fc(meta_features))\n",
        "x_gnn = F.relu(gcn_conv(x_gnn, edge_index))  # 🔄 Ahora con atención\n",
        "x_gnn = dropout(x_gnn)\n",
        "\n",
        "x_concat = torch.cat([text_embeddings, x_gnn], dim=1)\n",
        "x = F.relu(concat_fc1(x_concat))\n",
        "x = bn1(x)\n",
        "x = dropout(x)\n",
        "logits = F.log_softmax(output_fc(x), dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Entrenamiento del modelo híbrido BETO + GCN\n",
        "\n",
        "Se entrena la arquitectura que combina embeddings textuales (BETO) con metadatos procesados mediante una red neuronal de grafos (`GCNConv`).\n",
        "\n",
        "### 7.1 Configuración\n",
        "- **Loss:** `NLLLoss` (por uso de `log_softmax`)\n",
        "- **Optimizador:** Adam\n",
        "- **Épocas:** 20\n",
        "- **Métricas:** accuracy y pérdida en entrenamiento y validación\n",
        "\n",
        "### 7.2 Proceso por época\n",
        "1. Los metadatos se proyectan con `meta_fc` y se propagan en el grafo con `GCNConv`.\n",
        "2. Se concatenan con los embeddings de texto (`X_text_*`).\n",
        "3. La representación combinada pasa por capas densas (`concat_fc1` + `output_fc`).\n",
        "4. Se calcula la pérdida y se actualizan los pesos (entrenamiento).\n",
        "5. En validación, se replica el forward pass sin actualizar parámetros.\n",
        "\n",
        "### 7.3 Métricas\n",
        "Se registran precisión y pérdida por época para evaluar desempeño. El grafo se reconstruye dinámicamente en cada conjunto (`adj_train`, `adj_test`).\n",
        "\n",
        "> Este modelo aprende simultáneamente contenido y contexto, lo que mejora la detección de desinformación más allá del análisis puramente textual.\n"
      ],
      "metadata": {
        "id": "OH7Y7f7EOClm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOi91XduSeW_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch_geometric.utils import dense_to_sparse\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Tensors de train/test (NO recrearlos en cada epoch)\n",
        "x_meta_tr = torch.tensor(X_meta_train, dtype=torch.float32, device=device)\n",
        "x_meta_te = torch.tensor(X_meta_test,  dtype=torch.float32, device=device)\n",
        "x_txt_tr  = torch.tensor(X_text_train, dtype=torch.float32, device=device)\n",
        "x_txt_te  = torch.tensor(X_text_test,  dtype=torch.float32, device=device)\n",
        "\n",
        "y_tr = torch.tensor(y_train, dtype=torch.long, device=device)\n",
        "y_te = torch.tensor(y_test,  dtype=torch.long, device=device)\n",
        "\n",
        "# edge_index (fijo por split)\n",
        "edge_index_tr, _ = dense_to_sparse(torch.tensor(adj_enriched_train, dtype=torch.float32, device=device))\n",
        "edge_index_te, _ = dense_to_sparse(torch.tensor(adj_enriched_test,  dtype=torch.float32, device=device))\n",
        "\n",
        "\n",
        "# Criterio y optimizador\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.05)  # ← evita sobreconfianza\n",
        "optimizer = optim.Adam(\n",
        "    list(meta_fc.parameters()) +\n",
        "    list(gcn_conv.parameters()) +\n",
        "    list(concat_fc1.parameters()) +\n",
        "    list(output_fc.parameters()),\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-3                                  # ← regulariza (L2)\n",
        ")\n",
        "\n",
        "# Scheduler (reduce LR si val_loss no mejora)\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1)\n",
        "\n",
        "# ---------------------------\n",
        "# Loop con early stopping (por AUROC)\n",
        "# ---------------------------\n",
        "EPOCHS   = 20\n",
        "PATIENCE = 3\n",
        "best_state = None\n",
        "best_auc   = -np.inf\n",
        "best_vloss = np.inf\n",
        "stalled    = 0\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "train_accs,   val_accs   = [], []\n",
        "val_aurocs               = []\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    # ---- TRAIN ----\n",
        "    meta_fc.train(); gcn_conv.train(); concat_fc1.train(); output_fc.train()\n",
        "\n",
        "    # forward\n",
        "    x_gnn = F.relu(meta_fc(x_meta_tr))\n",
        "    x_gnn = F.relu(gcn_conv(x_gnn, edge_index_tr))\n",
        "    x_gnn = dropout(x_gnn)\n",
        "\n",
        "    x = torch.cat([x_txt_tr, x_gnn], dim=1)\n",
        "    x = dropout(F.relu(concat_fc1(x)))\n",
        "    logits = output_fc(x)                      # ← sin log_softmax\n",
        "\n",
        "    loss = criterion(logits, y_tr)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(            # ← evita explosión de gradientes\n",
        "        list(meta_fc.parameters())+\n",
        "        list(gcn_conv.parameters())+\n",
        "        list(concat_fc1.parameters())+\n",
        "        list(output_fc.parameters()),\n",
        "        max_norm=1.0\n",
        "    )\n",
        "    optimizer.step()\n",
        "\n",
        "    # métricas train\n",
        "    with torch.no_grad():\n",
        "        pred_tr = logits.argmax(dim=1)\n",
        "        acc_tr  = (pred_tr == y_tr).float().mean().item()\n",
        "\n",
        "    # ---- VAL ----\n",
        "    meta_fc.eval(); gcn_conv.eval(); concat_fc1.eval(); output_fc.eval()\n",
        "    with torch.no_grad():\n",
        "        x_gnn_v = F.relu(meta_fc(x_meta_te))\n",
        "        x_gnn_v = F.relu(gcn_conv(x_gnn_v, edge_index_te))\n",
        "        x_gnn_v = dropout(x_gnn_v)             # dropout desactivado en eval\n",
        "\n",
        "        xv = torch.cat([x_txt_te, x_gnn_v], dim=1)\n",
        "        xv = dropout(F.relu(concat_fc1(xv)))\n",
        "        logits_v = output_fc(xv)\n",
        "\n",
        "        vloss = criterion(logits_v, y_te)\n",
        "        pred_v = logits_v.argmax(dim=1)\n",
        "        acc_v  = (pred_v == y_te).float().mean().item()\n",
        "\n",
        "        # AUROC (prob de clase 1)\n",
        "        probs_v = torch.softmax(logits_v, dim=1)[:, 1].detach().cpu().numpy()\n",
        "        y_true  = y_te.detach().cpu().numpy()\n",
        "        try:\n",
        "            auc_v = roc_auc_score(y_true, probs_v)\n",
        "        except ValueError:\n",
        "            auc_v = np.nan  # por si alguna clase falta en val\n",
        "\n",
        "    # guardar métricas\n",
        "    train_losses.append(loss.item())\n",
        "    val_losses.append(vloss.item())\n",
        "    train_accs.append(acc_tr)\n",
        "    val_accs.append(acc_v)\n",
        "    val_aurocs.append(auc_v)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | \"\n",
        "          f\"TrainLoss {loss.item():.4f} Acc {acc_tr:.3f} | \"\n",
        "          f\"ValLoss {vloss.item():.4f} Acc {acc_v:.3f} AUROC {auc_v:.3f}\")\n",
        "\n",
        "    # Step del scheduler\n",
        "    scheduler.step(vloss.item())\n",
        "\n",
        "    # ---- Early stopping por AUROC (desempate por menor val_loss) ----\n",
        "    improved = False\n",
        "    if not np.isnan(auc_v):\n",
        "        if (auc_v > best_auc) or (np.isclose(auc_v, best_auc) and vloss.item() < best_vloss):\n",
        "            improved = True\n",
        "    else:\n",
        "        # si AUROC no es computable, usa solo val_loss\n",
        "        if vloss.item() < best_vloss:\n",
        "            improved = True\n",
        "\n",
        "    if improved:\n",
        "        best_auc, best_vloss = float(auc_v), float(vloss.item())\n",
        "        best_state = {\n",
        "            \"meta_fc\": meta_fc.state_dict(),\n",
        "            \"gcn_conv\": gcn_conv.state_dict(),\n",
        "            \"concat_fc1\": concat_fc1.state_dict(),\n",
        "            \"output_fc\": output_fc.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict()\n",
        "        }\n",
        "        stalled = 0\n",
        "    else:\n",
        "        stalled += 1\n",
        "        if stalled >= PATIENCE:\n",
        "            print(\"🛑 Early stopping (no mejora en AUROC/ValLoss).\")\n",
        "            break\n",
        "\n",
        "# Restaurar mejor checkpoint\n",
        "if best_state is not None:\n",
        "    meta_fc.load_state_dict(best_state[\"meta_fc\"])\n",
        "    gcn_conv.load_state_dict(best_state[\"gcn_conv\"])\n",
        "    concat_fc1.load_state_dict(best_state[\"concat_fc1\"])\n",
        "    output_fc.load_state_dict(best_state[\"output_fc\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Resultados del modelo híbrido (BETO + GCN)\n",
        "\n",
        "### 8.1 Curvas de entrenamiento\n",
        "\n",
        "Se visualizan las curvas de accuracy y pérdida durante 20 épocas para entrenamiento y validación.\n",
        "\n",
        "- **Accuracy:** El modelo alcanza más de 97% tanto en entrenamiento como validación, con curvas estables desde la época 6.\n",
        "- **Loss:** La pérdida cae rápidamente al inicio y se estabiliza en ambas fases, sin señales de sobreajuste.\n",
        "\n",
        "> Estas curvas indican una convergencia rápida y un excelente poder de generalización.\n"
      ],
      "metadata": {
        "id": "G0D4sRySOyTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy plot\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
        "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
        "plt.title(\"Accuracy over epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Loss plot\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Validation Loss\")\n",
        "plt.title(\"Loss over epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xYhv5SQYN_w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.1 Clasificación por clase\n",
        "- **Accuracy total:** 0.97\n",
        "- **Macro F1-score:** 0.97\n",
        "\n",
        "### 8.2 Matriz de confusión\n",
        "\n",
        "- **Recall (Fake):** 0.95 → El modelo detecta casi todas las noticias falsas.\n",
        "- **Precision (Fake):** 0.98 → Los falsos positivos son mínimos.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "twS4ypMcPCnN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vo852B9pShC0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Modo evaluación\n",
        "text_fc.eval()\n",
        "meta_fc.eval()\n",
        "gcn_conv.eval()\n",
        "concat_fc1.eval()\n",
        "ln1.eval()\n",
        "output_fc.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    x_gnn_test = F.relu(meta_fc(torch.tensor(X_meta_test, dtype=torch.float32).to(device)))\n",
        "    adj_dense_test = torch.tensor(adj_enriched_test, dtype=torch.float32).to(device)\n",
        "    edge_index_test, _ = dense_to_sparse(adj_dense_test)\n",
        "\n",
        "    x_gnn_test = F.relu(gcn_conv(x_gnn_test, edge_index_test))\n",
        "    # 🔹 sin dropout en test\n",
        "\n",
        "    text_input_test = torch.tensor(X_text_test, dtype=torch.float32).to(device)\n",
        "    x_text_test = F.relu(text_fc(text_input_test))   # 🔹 proyección como en train\n",
        "\n",
        "    x_concat_test = torch.cat([x_text_test, x_gnn_test], dim=1)\n",
        "\n",
        "    x_test = F.relu(concat_fc1(x_concat_test))\n",
        "    x_test = ln1(x_test)                             # 🔹 normalización como en train\n",
        "    logits_test = output_fc(x_test)                  # 🔹 sin log_softmax\n",
        "\n",
        "    pred_labels = logits_test.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "# Reporte de clasificación\n",
        "print(classification_report(y_test, pred_labels, target_names=[\"Real\", \"Fake\", \"Satira\"]))\n",
        "\n",
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_test, pred_labels)\n",
        "print(cm)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Real\", \"Fake\", \"Satira\"])\n",
        "disp.plot(cmap='Blues')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get prediction probabilities, not just classifications\n",
        "probs = F.softmax(logits_test, dim=1)\n",
        "fake_confidence = probs[:, 1].cpu().numpy()\n",
        "print(f\"Mean confidence for fake predictions: {fake_confidence[pred_labels==1].mean():.3f}\")\n",
        "print(f\"Mean confidence for real predictions: {fake_confidence[pred_labels==0].mean():.3f}\")"
      ],
      "metadata": {
        "id": "GvDcwuSKJlZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What real news is being misclassified as fake?\n",
        "false_positive_indices = np.where((y_test == 0) & (pred_labels == 1))[0]\n",
        "print(f\"False positive examples: {len(false_positive_indices)}\")\n",
        "# Examine these specific texts to understand the pattern"
      ],
      "metadata": {
        "id": "eEfYkG12JjZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53FG4dib-CcK"
      },
      "source": [
        "### 9. Conclusión\n",
        "\n",
        "El modelo híbrido supera significativamente al modelo textual puro (BETO + MLP), logrando un desempeño robusto en ambas clases. La integración de señales estructurales y lingüísticas permite mejorar la detección de desinformación, especialmente en casos más sutiles.\n",
        "\n",
        "> Este resultado valida la hipótesis central de la tesis: **el contexto estructural y narrativo aporta valor significativo al análisis automático de veracidad**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick BETO-only baseline test\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_baseline = LogisticRegression(max_iter=1000)\n",
        "lr_baseline.fit(X_text_train, y_train)\n",
        "beto_baseline_acc = lr_baseline.score(X_text_test, y_test)\n",
        "print(f\"BETO-only baseline accuracy: {beto_baseline_acc:.4f}\")"
      ],
      "metadata": {
        "id": "QPr47TBzIcvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = F.softmax(logits_test, dim=1).detach().cpu().numpy()\n",
        "y_score = probs[:, 1]  # Probabilidad de ser FAKE"
      ],
      "metadata": {
        "id": "rlQt59v4jKSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# y_test: tus etiquetas verdaderas (0 = real, 1 = fake, 2 = satira)\n",
        "# y_score: tus probabilidades de ser FAKE (columna 1)\n",
        "# For multi-class, roc_auc_score needs a multi_class strategy\n",
        "roc_auc = roc_auc_score(y_test, probs, multi_class='ovr', average='macro')\n",
        "print(f\"AUROC: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "id": "FEYMW3nMjMqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Assuming 'Fake' is class 1 and 'Real' and 'Satira' are other classes.\n",
        "# Plot ROC for 'Fake' class (label 1) against all other classes.\n",
        "# We need to convert the true labels to binary (1 for Fake, 0 otherwise)\n",
        "y_true_binary = (y_test == 1)\n",
        "# And use the probability of the Fake class\n",
        "y_score_fake = probs[:, 1]\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_true_binary, y_score_fake)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "# Use the macro-averaged AUROC calculated previously\n",
        "plt.plot(fpr, tpr, label=f\"AUROC (Fake vs Rest) = {roc_auc:.2f}\", color=\"darkorange\", lw=2)\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Curva ROC - Modelo Híbrido (Fake vs Rest)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LWGqD49mjOZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Benchmark del modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "QnLH-hDOdLY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jpposadas/FakeNewsCorpusSpanish.git"
      ],
      "metadata": {
        "id": "UoQBPe5ec1t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns=[\"CATEGORY\", \"SOURCE\", \"HEADLINE\", \"TEXT\", \"LINK\"]\n",
        "test = pd.read_excel(\"/content/FakeNewsCorpusSpanish/test.xlsx\", index_col = None, usecols=columns)\n",
        "\n",
        "test.head()"
      ],
      "metadata": {
        "id": "AyA5aZe4tPH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.DataFrame()\n",
        "df_test[\"TEXTO\"] = (test[\"HEADLINE\"].fillna(\"\").astype(str) + \". \" + test[\"TEXT\"].fillna(\"\").astype(str))\n",
        "df_test[\"LABEL\"] = test[\"CATEGORY\"].astype(str).str.lower().map({\"true\":0,\"real\":0,\"false\":1,\"fake\":1, \"satira\":2}).astype(int)\n",
        "df_test[\"FUENTE\"] = test[\"SOURCE\"].fillna(\"desconocido\").astype(str)\n",
        "\n",
        "# 3) FUENTE_COD (reusa el encoder del train si existe; si no, encódalo aquí)\n",
        "if \"le_fuente\" in globals():\n",
        "    fmap = {cls:i for i,cls in enumerate(le_fuente.classes_)}\n",
        "    unk  = fmap.get(\"desconocido\", 0)\n",
        "    df_test[\"FUENTE_COD\"] = df_test[\"FUENTE\"].map(lambda x: fmap.get(x, unk)).astype(int)\n",
        "else:\n",
        "    df_test[\"FUENTE_COD\"] = LabelEncoder().fit_transform(df_test[\"FUENTE\"])\n",
        "\n",
        "# 4) Features numéricas crudas\n",
        "df_test[\"LONGITUD\"]  = df_test[\"TEXTO\"].str.split().str.len().astype(float)\n",
        "df_test[\"POLARIDAD\"] = df_test[\"TEXTO\"].apply(get_sentiment).astype(float)   # usa tu misma función\n",
        "df_test[\"CLICKBAIT\"] = test[\"HEADLINE\"].fillna(\"\").astype(str).apply(clickbait_score).astype(float)\n",
        "\n",
        "df_test.head()\n"
      ],
      "metadata": {
        "id": "tfyyRGCzdPvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "df_test[['LONGITUD_NORM', 'POLARIDAD_NORM', 'CLICKBAIT_NORM']] = scaler.fit_transform(\n",
        "    df_test[['LONGITUD', 'POLARIDAD', 'CLICKBAIT']]\n",
        ")\n",
        "\n",
        "# Crear matriz metadata final\n",
        "metadata_gnn = np.concatenate([\n",
        "    df_test['FUENTE_COD'].values.reshape(-1,1),\n",
        "    df_test[['LONGITUD_NORM', 'POLARIDAD_NORM', 'CLICKBAIT_NORM']].values\n",
        "], axis=1)\n"
      ],
      "metadata": {
        "id": "HrlYqvFvlQS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head()"
      ],
      "metadata": {
        "id": "IkudPjIr4w9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_text_bench = generate_embeddings(df_test['TEXTO'])\n",
        "X_meta_bench = metadata_gnn.astype(np.float32)\n",
        "y_bench = df_test['LABEL'].to_numpy()\n",
        "\n",
        "# 2) Construir grafo (mismos umbrales que en tu código)\n",
        "fuentes_b = X_meta_bench[:, 0]\n",
        "fechas_b = X_meta_bench[:, 1]\n",
        "polaridades_b = X_meta_bench[:, 3]\n",
        "\n",
        "sim_text_b = cosine_similarity(X_text_bench)\n",
        "adj_text_b = (sim_text_b > 0.8).astype(np.float32)\n",
        "adj_fuente_b = np.equal.outer(fuentes_b, fuentes_b).astype(np.float32)\n",
        "adj_fecha_b = (np.abs(fechas_b[:, None] - fechas_b[None, :]) <= 0.05).astype(np.float32) if np.std(fechas_b) > 1e-6 else np.zeros_like(adj_text_b)\n",
        "adj_polaridad_b = (np.abs(polaridades_b[:, None] - polaridades_b[None, :]) <= 0.1).astype(np.float32)\n",
        "\n",
        "adj_bench = np.clip(adj_text_b + adj_fuente_b + adj_fecha_b + adj_polaridad_b, 0, 1)\n",
        "np.fill_diagonal(adj_bench, 0)"
      ],
      "metadata": {
        "id": "9tUTT45SpKlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_fc.eval(); gcn_conv.eval(); concat_fc1.eval(); output_fc.eval()\n",
        "with torch.no_grad():\n",
        "    # --- FIX DIMENSIONES METADATA (pad/recorte automático) ---\n",
        "    xmb = torch.tensor(X_meta_bench, dtype=torch.float32, device=device)\n",
        "    need = meta_fc.in_features\n",
        "    have = xmb.shape[1]\n",
        "    if have < need:\n",
        "        # rellenamos con 0.5 (valor neutro si usaste MinMaxScaler) al FINAL\n",
        "        pad = torch.full((xmb.size(0), need - have), 0.5, device=device)\n",
        "        xmb = torch.cat([xmb, pad], dim=1)\n",
        "    elif have > need:\n",
        "        # si sobran columnas, recorta\n",
        "        xmb = xmb[:, :need]\n",
        "\n",
        "    x_gnn_b = F.relu(meta_fc(xmb))\n",
        "    edge_index_b, _ = dense_to_sparse(torch.tensor(adj_bench, dtype=torch.float32, device=device))\n",
        "    x_gnn_b = dropout(F.relu(gcn_conv(x_gnn_b, edge_index_b)))\n",
        "    x_concat_b = torch.cat([torch.tensor(X_text_bench, dtype=torch.float32, device=device), x_gnn_b], dim=1)\n",
        "    x_b = dropout(F.relu(concat_fc1(x_concat_b)))\n",
        "    logits_b = F.log_softmax(output_fc(x_b), dim=1)\n",
        "    y_pred_b = logits_b.argmax(dim=1).cpu().numpy()\n"
      ],
      "metadata": {
        "id": "XrvmxoSppQR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_bench, y_pred_b, target_names=[\"Real\", \"Fake\", \"Satira\"]))"
      ],
      "metadata": {
        "id": "HET4QrGopbT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_benchmark = confusion_matrix(y_bench, y_pred_b)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_benchmark, display_labels=[\"Real\", \"Fake\", \"Satira\"])\n",
        "disp.plot(cmap='Blues')"
      ],
      "metadata": {
        "id": "sSBXjV7HphaH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}